#!/usr/bin/env npx tsx
// ============================================
// Frontend Evaluation Script
// í”„ë¡ íŠ¸ì—”ë“œ í’ˆì§ˆ í‰ê°€ ë„êµ¬
// ============================================

import { execSync, spawnSync } from 'child_process'
import { existsSync, readFileSync, writeFileSync, mkdirSync } from 'fs'
import { resolve } from 'path'

interface EvaluationResult {
  category: string
  score: number
  maxScore: number
  details: string[]
  passed: boolean
}

interface FrontendReport {
  timestamp: string
  overallScore: number
  results: EvaluationResult[]
  recommendations: string[]
}

const REPORT_DIR = resolve(process.cwd(), 'reports')

// ============================================
// Utility Functions
// ============================================

function runCommand(cmd: string, silent = true): { success: boolean; output: string } {
  try {
    const output = execSync(cmd, {
      encoding: 'utf-8',
      stdio: silent ? 'pipe' : 'inherit',
    })
    return { success: true, output }
  } catch (error) {
    const err = error as { stdout?: string; stderr?: string }
    return { success: false, output: err.stdout || err.stderr || '' }
  }
}

function printSection(title: string) {
  console.log('\n' + '='.repeat(50))
  console.log(`  ${title}`)
  console.log('='.repeat(50))
}

function printResult(result: EvaluationResult) {
  const status = result.passed ? 'âœ…' : 'âŒ'
  const percentage = ((result.score / result.maxScore) * 100).toFixed(1)
  console.log(`${status} ${result.category}: ${result.score}/${result.maxScore} (${percentage}%)`)
  result.details.forEach(detail => console.log(`   - ${detail}`))
}

// ============================================
// Evaluation Functions
// ============================================

function evaluateTypeScript(): EvaluationResult {
  printSection('TypeScript Type Check')

  const { success, output } = runCommand('pnpm tsc --noEmit 2>&1')

  if (success) {
    return {
      category: 'TypeScript',
      score: 100,
      maxScore: 100,
      details: ['ëª¨ë“  íƒ€ì… ê²€ì‚¬ í†µê³¼'],
      passed: true,
    }
  }

  const errorCount = (output.match(/error TS\d+/g) || []).length
  const score = Math.max(0, 100 - errorCount * 5)

  return {
    category: 'TypeScript',
    score,
    maxScore: 100,
    details: [`${errorCount}ê°œ íƒ€ì… ì˜¤ë¥˜ ë°œê²¬`],
    passed: errorCount === 0,
  }
}

function evaluateESLint(): EvaluationResult {
  printSection('ESLint Code Quality')

  const { success, output } = runCommand('pnpm eslint src --format json 2>&1')

  try {
    const results = JSON.parse(output)
    let errorCount = 0
    let warningCount = 0

    results.forEach((file: { errorCount: number; warningCount: number }) => {
      errorCount += file.errorCount
      warningCount += file.warningCount
    })

    const score = Math.max(0, 100 - errorCount * 10 - warningCount * 2)

    return {
      category: 'ESLint',
      score: Math.min(100, score),
      maxScore: 100,
      details: [
        `Errors: ${errorCount}`,
        `Warnings: ${warningCount}`,
      ],
      passed: errorCount === 0,
    }
  } catch {
    return {
      category: 'ESLint',
      score: success ? 100 : 50,
      maxScore: 100,
      details: success ? ['ê²€ì‚¬ ì™„ë£Œ'] : ['ESLint ì‹¤í–‰ ì˜¤ë¥˜'],
      passed: success,
    }
  }
}

function evaluateBundleSize(): EvaluationResult {
  printSection('Bundle Size Analysis')

  // Check if .next exists
  if (!existsSync('.next')) {
    return {
      category: 'Bundle Size',
      score: 0,
      maxScore: 100,
      details: ['ë¹Œë“œ í•„ìš” (pnpm build ì‹¤í–‰)'],
      passed: false,
    }
  }

  // Read build manifest if exists
  const manifestPath = '.next/build-manifest.json'
  if (existsSync(manifestPath)) {
    try {
      const manifest = JSON.parse(readFileSync(manifestPath, 'utf-8'))
      const pageCount = Object.keys(manifest.pages || {}).length

      return {
        category: 'Bundle Size',
        score: 80,
        maxScore: 100,
        details: [
          `${pageCount}ê°œ í˜ì´ì§€ ë²ˆë“¤`,
          'Bundle Analyzer: pnpm build:analyze ì‹¤í–‰',
        ],
        passed: true,
      }
    } catch {
      // Ignore parse errors
    }
  }

  return {
    category: 'Bundle Size',
    score: 50,
    maxScore: 100,
    details: ['ë¹Œë“œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¶„ì„ í•„ìš”'],
    passed: true,
  }
}

function evaluateAccessibility(): EvaluationResult {
  printSection('Accessibility (a11y)')

  // Check for common a11y patterns in components
  const { output } = runCommand('grep -r "aria-" src/components --include="*.tsx" | wc -l')
  const ariaCount = parseInt(output.trim()) || 0

  const { output: altOutput } = runCommand('grep -r "alt=" src/components --include="*.tsx" | wc -l')
  const altCount = parseInt(altOutput.trim()) || 0

  const score = Math.min(100, 50 + ariaCount * 2 + altCount * 5)

  return {
    category: 'Accessibility',
    score,
    maxScore: 100,
    details: [
      `ARIA ì†ì„±: ${ariaCount}ê°œ`,
      `Alt í…ìŠ¤íŠ¸: ${altCount}ê°œ`,
      'Lighthouse a11y ê²€ì‚¬ ê¶Œì¥',
    ],
    passed: score >= 70,
  }
}

function evaluatePerformancePatterns(): EvaluationResult {
  printSection('Performance Patterns')

  const checks = {
    useMemo: 0,
    useCallback: 0,
    lazyLoad: 0,
    imageOptimization: 0,
  }

  // Check for React optimization hooks
  const { output: memoOutput } = runCommand('grep -r "useMemo" src --include="*.tsx" | wc -l')
  checks.useMemo = parseInt(memoOutput.trim()) || 0

  const { output: callbackOutput } = runCommand('grep -r "useCallback" src --include="*.tsx" | wc -l')
  checks.useCallback = parseInt(callbackOutput.trim()) || 0

  // Check for lazy loading
  const { output: lazyOutput } = runCommand('grep -r "dynamic\\|lazy" src --include="*.tsx" | wc -l')
  checks.lazyLoad = parseInt(lazyOutput.trim()) || 0

  // Check for Next.js Image
  const { output: imageOutput } = runCommand('grep -r "next/image" src --include="*.tsx" | wc -l')
  checks.imageOptimization = parseInt(imageOutput.trim()) || 0

  const score = Math.min(100, 40 + checks.useMemo + checks.useCallback * 2 + checks.lazyLoad * 5 + checks.imageOptimization * 3)

  return {
    category: 'Performance Patterns',
    score,
    maxScore: 100,
    details: [
      `useMemo: ${checks.useMemo}ê°œ`,
      `useCallback: ${checks.useCallback}ê°œ`,
      `Lazy Loading: ${checks.lazyLoad}ê°œ`,
      `Image Optimization: ${checks.imageOptimization}ê°œ`,
    ],
    passed: score >= 60,
  }
}

function evaluateComponentTests(): EvaluationResult {
  printSection('Component Tests')

  const { output } = runCommand('find src -name "*.test.tsx" -o -name "*.spec.tsx" | wc -l')
  const testFileCount = parseInt(output.trim()) || 0

  const { output: componentOutput } = runCommand('find src/components -name "*.tsx" | wc -l')
  const componentCount = parseInt(componentOutput.trim()) || 0

  const coverage = componentCount > 0 ? (testFileCount / componentCount) * 100 : 0
  const score = Math.min(100, coverage * 2)

  return {
    category: 'Component Tests',
    score: Math.round(score),
    maxScore: 100,
    details: [
      `í…ŒìŠ¤íŠ¸ íŒŒì¼: ${testFileCount}ê°œ`,
      `ì»´í¬ë„ŒíŠ¸: ${componentCount}ê°œ`,
      `ì»¤ë²„ë¦¬ì§€: ${coverage.toFixed(1)}%`,
    ],
    passed: coverage >= 20,
  }
}

function evaluateDesignSystem(): EvaluationResult {
  printSection('Design System Compliance')

  // Check for hardcoded colors (should use Tailwind)
  const { output: hexOutput } = runCommand('grep -rE "#[0-9A-Fa-f]{6}" src/components --include="*.tsx" | wc -l')
  const hardcodedColors = parseInt(hexOutput.trim()) || 0

  // Check for inline styles
  const { output: styleOutput } = runCommand('grep -r "style={{" src/components --include="*.tsx" | wc -l')
  const inlineStyles = parseInt(styleOutput.trim()) || 0

  const deductions = hardcodedColors * 5 + inlineStyles * 3
  const score = Math.max(0, 100 - deductions)

  return {
    category: 'Design System',
    score,
    maxScore: 100,
    details: [
      `í•˜ë“œì½”ë”© ìƒ‰ìƒ: ${hardcodedColors}ê°œ (ê¶Œì¥: 0)`,
      `ì¸ë¼ì¸ ìŠ¤íƒ€ì¼: ${inlineStyles}ê°œ`,
    ],
    passed: hardcodedColors <= 5 && inlineStyles <= 10,
  }
}

// ============================================
// Main Execution
// ============================================

async function main() {
  console.log('\nğŸ¨ HEPHAITOS Frontend Evaluation')
  console.log('=' .repeat(50))
  console.log(`Started at: ${new Date().toISOString()}`)

  const results: EvaluationResult[] = []

  // Run all evaluations
  results.push(evaluateTypeScript())
  results.push(evaluateESLint())
  results.push(evaluateBundleSize())
  results.push(evaluateAccessibility())
  results.push(evaluatePerformancePatterns())
  results.push(evaluateComponentTests())
  results.push(evaluateDesignSystem())

  // Calculate overall score
  const totalScore = results.reduce((sum, r) => sum + r.score, 0)
  const maxScore = results.reduce((sum, r) => sum + r.maxScore, 0)
  const overallScore = Math.round((totalScore / maxScore) * 100)

  // Print results
  printSection('Evaluation Results')
  results.forEach(printResult)

  // Overall score
  printSection('Overall Score')
  const grade = overallScore >= 90 ? 'A' : overallScore >= 80 ? 'B' : overallScore >= 70 ? 'C' : overallScore >= 60 ? 'D' : 'F'
  console.log(`\n  ğŸ“Š Frontend Score: ${overallScore}/100 (Grade: ${grade})`)

  // Recommendations
  const recommendations: string[] = []
  if (results.find(r => r.category === 'TypeScript' && !r.passed)) {
    recommendations.push('TypeScript íƒ€ì… ì˜¤ë¥˜ ìˆ˜ì • í•„ìš”')
  }
  if (results.find(r => r.category === 'ESLint' && !r.passed)) {
    recommendations.push('ESLint ì˜¤ë¥˜ ìˆ˜ì • í•„ìš”')
  }
  if (results.find(r => r.category === 'Component Tests' && !r.passed)) {
    recommendations.push('ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ ì¶”ê°€ ê¶Œì¥')
  }
  if (results.find(r => r.category === 'Design System' && !r.passed)) {
    recommendations.push('Tailwind í† í° ì‚¬ìš© ê¶Œì¥ (í•˜ë“œì½”ë”© ìƒ‰ìƒ ì œê±°)')
  }

  if (recommendations.length > 0) {
    printSection('Recommendations')
    recommendations.forEach((rec, i) => console.log(`  ${i + 1}. ${rec}`))
  }

  // Save report
  if (!existsSync(REPORT_DIR)) {
    mkdirSync(REPORT_DIR, { recursive: true })
  }

  const report: FrontendReport = {
    timestamp: new Date().toISOString(),
    overallScore,
    results,
    recommendations,
  }

  const reportPath = resolve(REPORT_DIR, `frontend-${Date.now()}.json`)
  writeFileSync(reportPath, JSON.stringify(report, null, 2))
  console.log(`\nğŸ“„ Report saved: ${reportPath}`)

  // Exit with appropriate code
  process.exit(overallScore >= 70 ? 0 : 1)
}

main().catch(console.error)
